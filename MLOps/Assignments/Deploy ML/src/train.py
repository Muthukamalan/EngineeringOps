from pathlib import Path
import logging
import os 
import torch
import hydra
from omegaconf import DictConfig
import lightning as L
from lightning.pytorch.loggers import Logger
from typing import List


import rootutils

# Setup root directory
root = rootutils.setup_root(__file__, indicator=".project-root", pythonpath=True)
# ------------------------------------------------------------------------------------ #
# the setup_root above is equivalent to:
# - adding project root dir to PYTHONPATH
#       (so you don't need to force user to install project as a package)
#       (necessary before importing any local modules e.g. `from src import utils`)
# - setting up PROJECT_ROOT environment variable
#       (which is used as a base for paths in "configs/paths/default.yaml")
#       (this way all filepaths are the same no matter where you run the code)
# - loading environment variables from ".env" in root dir
#
# you can remove it if you:
# 1. either install project as a package or move entry files to project root dir
# 2. set `root_dir` to "." in "configs/paths/default.yaml"
#
# more info: https://github.com/ashleve/rootutils
# ------------------------------------------------------------------------------------ #


# Imports that require root directory setup
from src.utils.logging_utils import setup_logger, task_wrapper

log = logging.getLogger(__name__)


def instantiate_callbacks(callback_cfg: DictConfig) -> List[L.Callback]:
    callbacks: List[L.Callback] = []
    if not callback_cfg:
        log.warning("No callback configs found! Skipping..")
        return callbacks

    for _, cb_conf in callback_cfg.items():
        if "_target_" in cb_conf:
            log.info(f"Instantiating callback <{cb_conf._target_}>")
            callbacks.append(hydra.utils.instantiate(cb_conf))

    return callbacks


def instantiate_loggers(logger_cfg: DictConfig) -> List[Logger]:
    loggers: List[Logger] = []
    if not logger_cfg:
        log.warning("No logger configs found! Skipping..")
        return loggers

    for _, lg_conf in logger_cfg.items():
        if "_target_" in lg_conf:
            log.info(f"Instantiating logger <{lg_conf._target_}>")
            loggers.append(hydra.utils.instantiate(lg_conf))

    return loggers


@task_wrapper
def train(
    cfg: DictConfig,
    trainer: L.Trainer,
    model: L.LightningModule,
    datamodule: L.LightningDataModule,
):
    log.info("Starting training!")
    trainer.fit(model, datamodule)
    train_metrics = trainer.callback_metrics
    log.info(f"Training metrics:\n{train_metrics}")


@task_wrapper
def test(
    cfg: DictConfig,
    trainer: L.Trainer,
    model: L.LightningModule,
    datamodule: L.LightningDataModule,
):
    log.info("Starting testing!")
    if trainer.checkpoint_callback.best_model_path:
        log.info(
            f"Loading best checkpoint: {trainer.checkpoint_callback.best_model_path}"
        )
        test_metrics = trainer.test(
            model, datamodule, ckpt_path=trainer.checkpoint_callback.best_model_path
        )
    else:
        log.warning("No checkpoint found! Using current model weights.")
        test_metrics = trainer.test(model, datamodule=datamodule, verbose=True)
    log.info(f"Test metrics:\n{test_metrics}")
    return test_metrics


@hydra.main(version_base="1.3", config_path="../configs", config_name="train")
def main(cfg: DictConfig):
    # print(OmegaConf.to_yaml(cfg=cfg))
    print(cfg.paths.output_dir)

    # Set up paths
    log_dir = Path(cfg.paths.log_dir)

    # Set up logger
    setup_logger(log_dir / "train_log.log")

    # Initialize DataModule
    log.info(f"Instantiating datamodule <{cfg.data._target_}>")
    datamodule: L.LightningDataModule = hydra.utils.instantiate(cfg.data)
    datamodule.setup()
    # Initialize Model
    log.info(f"Instantiating model <{cfg.model._target_}>")
    model: L.LightningModule = hydra.utils.instantiate(cfg.model)

    # Set up callbacks
    callbacks: List[L.Callback] = instantiate_callbacks(cfg.get("callbacks"))

    # Set up loggers
    loggers: List[Logger] = instantiate_loggers(cfg.get("logger"))

    # Initialize Trainer
    log.info(f"Instantiating trainer <{cfg.trainer._target_}>")
    trainer: L.Trainer = hydra.utils.instantiate(
        cfg.trainer,
        callbacks=callbacks,
        logger=loggers,
    )

    # # Train the model
    if cfg.get("train"):
        train(cfg, trainer, model, datamodule)

    # # Test the model
    if cfg.get("test"):
        test_metrics = test(cfg, trainer, model, datamodule)


    if cfg.get('script',False):
        imgs,lbls = next(iter(datamodule.train_dataloader()) )

        scripted_model = model.to_torchscript(method='trace',example_inputs=imgs)
        model_file_path:str = os.path.join( f"{cfg.paths.root_dir}","samples","checkpoints", "mambaout.pt" )
        if os.path.isfile( model_file_path ):
            os.remove(model_file_path)
        torch.jit.save(scripted_model, model_file_path)
        print(f"torch script model saved: {model_file_path=}")

        onnx_model_file_path:str = os.path.join( f"{cfg.paths.root_dir}","samples","checkpoints", "mambaout.onnx" )
        model.to_onnx(file_path=onnx_model_file_path,input_sample=imgs, export_params=True,verbose=True, dynamic_axes={'input': {0: 'batch'}},input_names=['input'],output_names=['output'])
        print(f"onnx model saved: {onnx_model_file_path}")

        #######################################################################################################################
        # Once you have the exported model, you can run it on your ONNX runtime in the following way:

        # import onnxruntime
        # ort_session = onnxruntime.InferenceSession(filepath)
        # input_name = ort_session.get_inputs()[0].name
        # ort_inputs = {input_name: np.random.randn(1, 64)}
        # ort_outs = ort_session.run(None, ort_inputs)
        #######################################################################################################################        
        
    return test_metrics[0][
        "test/loss_epoch"
    ]  # returning train_loss for optuna to compare 'test/acc_epoch','test/loss_epoch'
    # plot_confusion_matrix(model=model,datamodule=datamodule)


if __name__ == "__main__":
    main()
